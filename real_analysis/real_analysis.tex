\documentclass[11pt,oneside,titlepage]{article}
\title{My real analysis exercises}
\usepackage{amsmath,amssymb}
\usepackage{geometry}
\author{Evgeny Markin}
\date{2022}

\begin{document}
\maketitle

Exercises are from UTM-040 Understanding analysis by Stephen Abbott. Edition is
unknown, but the date in the preface is August 2000.

\section*{4.4.1}

\subsection*{{a}}
\textit{Show that $f(x) = x^{3}$ is continuous on all of \textbf{R}.}

In order to show, that $f$ is continous we need to show, that $\forall
\epsilon \in \textbf{R}$ $\exists \delta$ s.t.
$$|x - c| < \delta \to |f(x) - f(c)| < \epsilon$$

Let's rewrite the first formula

$$ |f(x) - f(c)| = |x^{3} - c^{3}| = |(x - c)(x^{2} + cx + c^{2})| =
|x - c||x^{2} + cx + c^{2}|$$

We can put $|x - c|$ can be as small as we want it to be. Therefore we need
an upper bound for $|x^{2} + cx + c^{2}|$.

$$|x^{2} + cx + c^{2}| \leq |x^{2}| + |cx| + |c^{2}| \leq (|c| + 1)^{2} +
|c|(|c| + 1) + |c|^{2}$$



Therefore if we take
$\delta = min\{1, \epsilon/((|c| + 1)^{2} + |c|(|c| + 1) + |c|^{2})\}$
then
$$|x^3 - c^3| = |x-c||x^2 + cx + c^2| \leq \epsilon \frac{((|c| + 1)^{2} +
  |c|(|c| + 1) + |c|^{2}) }{ ((|c| + 1)^{2} + |c|(|c| + 1) + |c|^{2}})
= \epsilon$$

Therefore $f(x) = x ^3$ is continous on \textbf{R}.

\subsection*{(b)}
\textit{Argue, using Theorem 4.4.6, that f is not uniformly continuous
  on \textbf{R}}


\textbf{Theorem 4.4.6 (Sequential Criterion for Nonuniform Continuity).} A
function $f:A \to \textbf{R}$ fails to be uniformly continuous on $A$ if
$\exists \epsilon > 0 $ and  two sequences $(x_n)$ and $(y_n)$ in $A$
satisfying

$|x_n - y_n| \to 0$ $but$ $|f(x_n) - f(y_n) \leq \epsilon_0$

In order to show that $f(x) = x^3$ is not uniformly continous on
\textbf{R} let us use sequences

$$x_n = n$$
$$y_n = (n + 1/n)$$

Firstly
$$ |x_n - y_n| = |n - n - 1/n| = |-1/n| = 1/n \to 0$$

on the other hand

$$|f(x_n) - f(y_n)| = |n ^ 3 - (n + 1/n) ^ 3| = |n^3 - (n^3 + 3 \frac{n^2}{n}
+ 3 \frac{n}{n^2} + \frac{1}{n^3})| = $$
$$ = |-3n - \frac{3}{n} - \frac{1}{n^3} | \leq |3n| \to \infty$$

rmaxima seems to eraborate this statement, therefore  $|x_n - y_n| \to 0$
but $|f(x_n) - f(y_n) \to \infty$

Therefore $f(x) = x^3$ is not uniformly continous on \textbf{R}.

\subsection*{(c)}
\textit{Show that $f$ is uniformly continuous on any bounded subset
  of \textbf{R}.}

Suppose that $A \subset \textbf{R}$ and $\exists M \in \textbf{R}$ s.t.
$\forall x \in A$ $x \leq M$ (i.e. $A$ is bounded $M$)

Then, $\forall c \in A$ and $\forall \epsilon \in \textbf{R}$
$$\frac{\epsilon}{((|M| + 1)^{2} + |M|(|M| + 1) + |M|^2}  \leq
\frac{\epsilon}{((|c| + 1)^{2} + |c|(|c| + 1) + |c|^2} $$

Therefore if we take
$$\delta = min\{1, \frac{\epsilon}{((|M| + 1)^{2} + |M|(|M| + 1) + |M|^2}\} $$
then $|x - c| < \delta$ implies, that $ |f(x) - f(c)| < \epsilon$, therefore
making $f(x)$ uniformly continous by definition


\section*{4.4.2}
\textit{Show that $f(x) = 1/x^3$  is uniformly continous on the set
  $[1, \infty)$, but is not on the set $(0, 1]$}

In order to show, that $f(x)$ is continous on the set $[1, \infty)$ let us
first prove that it is just continous, with the hope that $\delta$ is not
depentant on $x$

$$ |\frac{1}{x^3} - \frac{1}{c^3}| = |\frac{c^3 - x^3}{x^3c^3}| =
|\frac{(c - x)(x^2 + cx + c^2)}{x^3c^3}|
= |(c - x) \frac{x^2 + cx + c^2}{x^3c^3}| =
|c - x||\frac{x^2 + cx + c^2}{x^3c^3}| =$$
$$ = |x - c||\frac{x^2 + cx + c^2}{x^3c^3}| $$

Therefore we need to show that if $\delta$ is bounded above at 1, then
$|\frac{x^2 + cx + c^2}{x^3c^3}|$ is bounded above at $[1, \infty)$ by
some constant, but  $(0, 1]$ isn't.

$$ |\frac{x^2 + cx + c^2}{x^3c^3}| = |\frac{1}{c^3 x} + \frac{1}{c^2x^2}
+ \frac{1}{cx^3}| \leq
|\frac{1}{c^3 x}| + |\frac{1}{c^2x^2}| + |\frac{1}{cx^3}|
$$

for $x \in [1, \infty)$ each of those fractions are bounded above by 1,
therefore for $x \in [1, \infty)$

$$ |\frac{x^2 + cx + c^2}{x^3c^3}| \leq 3 $$

therefore if we pick $\delta < \epsilon / 3 $ then it follows, that
$|f(x) - f(c)| < \epsilon$ for $x \in [1, \infty)$

on the other hand,

$$ \lim_{x \to 0}(|\frac{x^2 + cx + c^2}{x^3c^3}|) \to \infty  $$

Therefore we will need smaller deltas as we approach 0; to put it more
concretely let's use the theorem for
\textbf{Sequential Criterion for Nonuniform Continuity}.

Let us pick
$$x_n = 1/n$$
$$y_n = 1/(n + 1)$$

then

$$|x_n - y_n| = |\frac{1}{n} - \frac{1}{n + 1}| = |\frac{n + 1 - n}{n(n + 1)}|
= |\frac{1}{n ^ 2 + 1}| \to 0$$

but

$$ |f(x_n) - f(y_n)| = |1/(\frac{1}{n})^3 - 1/(\frac{1}{n + 1})^3| = |1/(\frac{1}{n^3}) - 1/(\frac{1}{(n + 1)^3})| =  |n^3 - (n + 1)^3| =  $$
$$ = |n^3 - (n ^ 3 + 3 n^2 + 3 n + 1)| = |3n^2 + 3n + 1| \to \infty$$

therefore by \textbf{4.4.6} $f(x)$ is not uniformly continous on $(0, 1]$, as desired

\section*{4.4.3}
\textit{Furnish the details (including an argument for Exercise 3.3.1 if it is not already done) for the proof of the Extreme Value Theorem (Theorem 4.4.3).}

Let us first complete 3.3.1

\textit{Exercise 3.3.1. Show that if K is compact, then sup K and inf K both exist and are elements of K.}

Because $K$ is compact, it is both closed and bound; therefore, because it is bounded,


$$ \exists M \in \textbf{R} > 0 :  \forall x \in K $$
$$ |x| \leq M $$


Therefore there exist lower and upper bound of $K$. Therefore, by axiom of completenss, there exist
both $sup(K)$ and $inf(K)$ (i.e. both least upper bound and greatest lower bound)

Now let's prove that there exists a sequence that converges to either $sup(k)$ or $inf(k)$.

To be continued...


\section*{4.2.1}
\textit{Use Definition 4.2.1 to supply a proof for the following limit statements.}

(a) $\lim_{x \to 2}(2x + 4) = 8$.

(b) $\lim_{x\to0} x^3 = 0$.

(c) $\lim_{x\to2} x^3 = 8$.

(d) $lim_{x\to\pi}[[x]] = 3$, where [[x]] denotes the greatest integer less than or
equal to x.

Let's first state Definition 4.2.1

\textbf{Definition 4.2.1.} Let $f : A \to \textbf{R}$, and let $c$ be a limit point of the domain $A$. We say that $\lim_{x\to c} f(x) = L$ provided that, for all $\epsilon > 0$, there exists
a $\delta > 0$ such that whenever $0 < |x - c| < \delta$ (and $x \in A$) it follows that $|f(x) - L| < \epsilon$.

(a):
$$ |f(x) - L| = |2 x + 4 - 8| = |2 x - 4| = 2|x - 2| < \epsilon $$
$$ |x-2| < \frac{\epsilon}{2}$$

$$  \delta = \frac{\epsilon}{2} \to |2 x + 4 - 8| < \epsilon $$

as desired.

(b):
$$ |f(x) - L| = |x^3 - 0| = |x^3| = |x|^3 < \epsilon $$
$$ |x| < \sqrt[3]{\epsilon}{} $$
$$ \delta = \sqrt[3]{\epsilon} \to |x^3| < \epsilon $$

as desired.

(c):
$$ |f(x) - L| = |x^3 - 8| = |(x - 2)(x^2 + 2x + 4)| = |x-2||x^2 + 2x + 4| < \epsilon $$
$$|x-2| < \frac{\epsilon}{|x^2 + 2x + 4|} $$

Suppose that we set the maximum delta at 1; then upper bound for $|x^2 + 2x + 4|$ is:

$$ |x^2 + 2x + 4| \leq |x^2| + |2x| + 4 = |x|^2 + 2|x| + 4 \leq (|c| + 1)^2 + 2(|c| + 1) + 4 =$$
$$= (2 + 1)^2 + 2(2 + 1) + 4 = 9 + 6 + 4 = 19
$$

Therefore

$$\delta = min\{1, \epsilon/19\} \to |x^3 - 8| = |x-2||x^2 + 2x + 4| < \frac{\epsilon}{19} * 19 = \epsilon $$

as desired.

(d):

$$ |[[x]] - 3| = [[0.1415926...]] = 0 < \epsilon $$

Suppose that we pick $\delta = 0.1$, then any $x \in V_{\delta}$ will satisfy $|[[x]] - 3| = 0 < \epsilon $
for any $\epsilon > 0$ as desired.

\section*{4.2.2}
\textit{Assume a particular $\delta > 0$ has been constructed as a suitable response
  to a particular $\epsilon$ challenge. Then, any larger/smaller (pick one) $\delta$ will also suffice.}

Smaller. This follows from the fact, that
$$\delta_1 < \delta_2 \to V_{\delta_1} \subset V_{\delta_2}$$

\section*{4.2.3}
\textit{Use Corollary 4.2.5 to show that each of the following limits does not exist.}

(a) $\lim_{x\to0} |x|/x$

(b) $\lim_{x\to 1} g(x)$ where $g$ is Dirichlet’s function from Section 4.1.

I'll not state corollary 4.2.5  function here, because it's tedious, but it'll be obvious which corollary I'm talking about by the context.


(a): let
$$(x_n) = 1/n$$
$$(y_n) = -1/n$$
then
$$(x_n) \to 0;(y_n) \to 0$$
but
$$|x_n| / x_n = 1$$
$$|y_n| / y_n = -1$$
therefore the limit does not exist.

(b):

The Dirichlet function is
\begin{equation}
D(x)=
    \begin{cases}
        1 & \text{if } x \in \textbf{Q}\\
        0 & \text{if } x \notin \textbf{Q}
    \end{cases}
\end{equation}

let
$$(x_n) = 2/n + 1$$
$$(y_n) = \sqrt{2}/n + 1$$

then

$$(x_n) \to 1;(y_n) \to 1$$

but

$$(x_n) = 2/n + 1 \in \textbf{Q}$$
$$(y_n) = \sqrt{2}/n + 1 \notin \textbf{Q}$$

therefore

$$ D(x_n) = 1$$
$$ D(y_n) = 0$$

thus the function is not continous at 1

\section*{4.2.4}
\textit{Review the definition of Thomae’s function t(x) from Section 4.1.}

\textit{(a) Construct three different sequences $(x_n)$, $(y_n)$, and $(z_n)$, each of which converges to 1 without using the number 1 as a term in the sequence.}

\textit{(b) Now, compute $\lim t(x_n)$, $\lim t(y_n)$, and $\lim t(z_n)$.}

\textit{(c) Make an educated conjecture for $\lim_{x\to1} t(x)$, and use Definition 4.2.1B
  to verify the claim. Given $\epsilon > 0$, consider the set of points
$\{x \in \textbf{R} : t(x)  \epsilon\}$.  Argue that all the points in this set are isolated.}


The definition of  Thomae function is
\begin{equation}
t(x)=
    \begin{cases}
      1 & \text{if } x = 0\\
      1/n & \text {if } x = m/n \in \textbf{Q} \text{\textbackslash} \{0\} \\
      0 & \text{if } x \notin \textbf{Q}
    \end{cases}
\end{equation}

(a): Let our three sequences be

$$ (x_n) = n/(n + 1)$$
$$ (y_n) = (n + 1)/n$$
$$ (z_n) = \sum_{i=1}^{n}{\frac{1}{2^n}}$$

(b):
$$t(x_n) = \{1/2, 1/3, 1/4, 1/5, 1/6, 1/7 ...\}$$
$$t(y_n) = \{1, 1/2, 1/3, 1/4, 1/5, 1/6 ...\}$$
$$t(z_n) = \{1/2, 1/4, 1/8, 1/16 ...\}$$

(c): The educated conjecture here is that $\lim_{x \to 1} t(x) = 0$

In order to prove that conjecture author suggests, that we use $\epsilon-\delta$ definition. Let's try
it;

$$ |t(x)| < \epsilon$$

For all $\epsilon \in \textbf{R} > 0$

Therefore by archimedes property there exists a number $n \in \textbf{N}$ s.t. $\frac{1}{n} < \epsilon$.
Thus suppose that we have $\delta = 1/n$. Then our proposition is that 

$$\forall b \in (1 - 1/n; 1 + 1/n) \to |t(b)| < \epsilon$$

If $b \notin \textbf{Q} $ then $t(b) = 0$ and therefore $|t(b)| < \epsilon$; therefore we need to prove,
that any number $b = m_1/n_1 \in (1 - 1/n; 1 + 1/n) \cap \textbf{Q}$ is such, that $|t(b)| = 1/n_1 < 1/n$.
Also suppose $m_1 = n_1 + k$ (it's worth noting that in this case $k \in \textbf{Z}$); then

$$ 1 - \frac{1}{n} < \frac{m_1}{n_1} < 1 + \frac{1}{n}$$
$$ 1 - \frac{1}{n} < \frac{n_1 + k}{n_1} < 1 + \frac{1}{n}$$
$$ 1 - \frac{1}{n} < 1 + \frac{k}{n_1} < 1 + \frac{1}{n}$$
$$ - \frac{1}{n} <  \frac{k}{n_1} <  \frac{1}{n}$$
$$ |\frac{k}{n_1}| <  \frac{1}{n}$$
$$ |k||\frac{1}{n_1}| = |k||t(\frac{1}{n_1})| <  \frac{1}{n}$$

therefore because $k \in \textbf{Z}$

$$ |t(\frac{1}{n_1})| = |\frac{1}{n_1}| <  \frac{1}{n|k|} < \frac{1}{n}$$

thus for each $\epsilon > 0$ we can find a corresponding $\delta > 0$ as desired.

\section*{4.2.5}
Suppose that $\lim_{x \to c} f(x) = L$ and $\lim_{x \to c} g(x) = M$

$(ii)$ $\lim_{x \to c}[f(x) + g(x)] = L + M$

$(iii)$ $\lim_{x \to c}[f(x) g(x)] = L M$

(a)\textit{ Supply the details for how Corollary 4.2.4 part (ii) follows from the sequential criterion for functional limits in Theorem 4.2.3 and the Algebraic Limit Theorem for sequences proved in Chapter 2.}

From the algebraic limit theorem we know, that if $(a_n) \to a$ and $(b_n) \to b$ then

$$(a_n) + (b_n) = a + b$$

We also know, that for any sequence $(c_n) \to c$ it is true, that $f(c_n) \to L$ and $g(c_n) \to M$;
therefore by the algebraic limit theorem

$$f(c_n) + g(c_n) = L + M$$

for any sequence $(c_n) \to c$. Therefore we can state that

$$\lim_{x \to c}(f(x) + g(x)) = L + M $$

as desired

\textit{(b) Now, write another proof of Corollary 4.2.4 part (ii) directly from Definition 4.2.1 without using the sequential criterion in Theorem 4.2.3.}

$\lim_{x \to c} f(x) = L$ and $\lim_{x \to c} g(x) = M$; therefore for any $\epsilon_1 > 0$ we can find $\delta_1 > 0$ s.t.

$$ |x - c| < \delta_1 \to |f(x) - L| < \epsilon_1 $$

Also for the same $\epsilon_1$ there exist $\delta_2 > 0$ s.t.

$$ |x - c| < \delta_2 \to |g(x) - M| < \epsilon_1 $$

let $\delta_3 = min\{\delta_1, \delta_2\}$; then it is true that 

$$ |x - c| < \delta_3 \to |f(x) - L| < \epsilon_1 $$
$$ |x - c| < \delta_3 \to |g(x) - M| < \epsilon_1 $$

because $V_{\delta_1} \subseteq V_{\delta_3} $ and $V_{\delta_2} \subseteq V_{\delta_3} $

therefore

$$|f(x) - L| + |g(x) - M| < 2 \epsilon_1$$

Therefore 

$$ |f(x) + g(x) - L -  M| = |f(x) - L + g(x) - M| \leq |f(x) - L| + |g(x) - M| < 2 \epsilon_1 $$

Thus for any $\epsilon > 0$ there exist corresponding $\epsilon_1 = \frac{\epsilon}{2}$ for which there
exist corresponding $\delta = min\{\delta_1, \delta_2\}$ (where $\delta_1$ is a delta for $f(x)$ and
$\delta_2$ is a delta for $g(x)$) which satisfies

$$|x - c| < \delta \to |f(x) + g(x) - (L + M)| < \epsilon$$

therefore $\lim_{x \to c}(f(x) + g(x)) = L + M$ as desired.

\textit{(c) Repeat (a) and (b) for Corollary 4.2.4 part (iii).}

(a):

From the algebraic limit theorem we know, that if $(a_n) \to a$ and $(b_n) \to b$ then

$$(a_n) (b_n) = a  b$$

We also know, that for any sequence $(c_n) \to c$ it is true, that $f(c_n) \to L$ and $g(c_n) \to M$;
therefore by the algebraic limit theorem

$$f(c_n)  g(c_n) = L M$$

for any sequence $(c_n) \to c$. Therefore we can state that

$$\lim_{x \to c}(f(x)g(x)) = L M $$

as desired

(b):

$\lim_{x \to c} f(x) = L$ and $\lim_{x \to c} g(x) = M$;

In  order to prove the needed limit let's first use some algebra
$$ |f(x)g(x) - LM| = $$
$$ |f(x)g(x) + f(x)M - f(x)M - LM| = $$
$$|f(x)(g(x) - M) + M(f(x) - L)| \leq
|f(x)(g(x) - M)| + | M(f(x) - L)| = $$
$$|f(x)||g(x) - M| + |M||f(x) - L|  $$

our strategy is to show that both elements of the last sum are less or equal to $\epsilon/2$

Let $\epsilon > 0$.

$$ |M||f(x) - L| < \frac{\epsilon}{2}$$
If $M = 0$ then the abovementioned inequality always holds and we are free to choose any $\delta_1$;

Otherwise tet us pick $\delta_1$ such that inequality
$$ |f(x) - L| < \frac{\epsilon}{2|M|}$$
holds.

The next step is a little bit more complicated because we need to work with $f(x)$; let us pick y = 1;
then because $\lim_{x \to c}f(x) = L$ we know that there exists $\delta_2$ s.t. $|x - c| < \delta_2
\to |f(x) - L| < 1$. 

Therefore

$$|f(x) - L| < 1$$

Little sidenote: let's prove that 
$$ |a - b| < c \to |a| < |b| + c  $$

Firstly some preliminary stuff
$$|a - b| \geq 0 \to c > |a - b| > 0 \to c > 0$$

$$|a - b| < c \to -c < a - b < c$$
$$b -c < a  < b + c$$

Now let's see all the cases for $a, b \in \textbf{R}$

if $a \geq 0$ and $b \geq 0$ then
$$a < b + c$$
$$|a| < |b| + c$$

if $a < 0$ and $b \geq 0$ then
$$ b + c \geq 0 > a$$
$$a < b + c$$
$$|a| < |b| + c$$

if $a \geq 0$ and $b < 0$ then
$$b -c < a  < b + c$$
$$-b +c > -a  > -b - c$$
$$|b| +c > -a  > |b| - c$$
$$-|b| - c  < a  <  c - |b|$$
$$|a|  <  c - |b| \leq c + |b|$$
$$|a|  <  c + |b|$$

if $a < 0$ and $b < 0$ then
$$b -c < a  < b + c$$
$$-b + c > -a  > -b - c$$
$$|b| + c > |a|  > |b| - c$$
$$|b| + c > |a|$$
$$|a| < |b| + c$$

Therefore $\forall a,b\in \textbf{R}$
$$|a - b| < c \to |a| < |b| + c$$
as desired.

Back to our exercise: 

$$|f(x) - L| < 1$$
$$|f(x)| < |L| + 1$$

Therefore we can state that upper bound for our $|f(x)|$ with $\epsilon = 1$ is $|L| + 1$

Thus if we pick $\delta_2$ sufficient for

$$|g(x) - M| < \frac{\epsilon}{2(|L| + 1)}$$

therefore if we pick $\delta = min\{\delta_1, \delta_2\}$ then

$$|x - c| < \delta \to $$
$$|f(x)g(x) - LM| \leq |f(x)||g(x) - M| + |M||f(x) - L| <  \frac{\epsilon}{2} +
\frac{\epsilon}{2} = \epsilon  $$

therefore $\lim_{x \to c}[f(x) g(x)] = LM$ as desired

\section*{4.2.6}
\textit{Let $g: A\to \textbf{R}$ and assume that $f$ is bounded function on $A \subseteq \textbf{R}$
  (i.e. there exists $M > 0$ satisfying $|f(x| \leq M$ for all $x \in A$). Show that
  if $\lim_{x \to c}g(x) = 0$, then $\lim_{x \to c}g(x)f(x) = 0$ as well.}

Here we can't use an intuitive approach of just using algebraic limit theorem because $f(x)$ may
not hav limit at $c$.
Anyways we proceed by $\epsilon-\delta$ approach.

Therefore we need to show that
$$\exists \delta: |f(x)g(x)| < \epsilon$$

First of all,
$$ |f(x)g(x)| = |f(x)||g(x)|$$

Then we notice, that because $f(x)$ is bounded

$$\exists M \in \textbf{R} > 0: |f(x)| \leq M$$
therefore
$$|f(x)||g(x)| < |M||g(x)| = M|g(x)|$$

therefore if we pick $\delta$ sufficient for $|g(x)| < \frac{\epsilon}{M}$ then it follows that

$$|f(x)g(x)| \leq M|g(x)| < \epsilon$$

therefore
$$\forall \epsilon \in \textbf{R} \exists \delta : |x - c| < \delta \to |f(x)g(x)| < \epsilon$$

therefore

$$\lim_{x \to c}[f(x)g(x)] = 0$$
as desired.

\section*{4.2.7}
\textit{(a) The statement $\lim_{x \to 0}1/x^2 = \infty$ certainly makes intuitive sense. Construct a rigirius definition in the "challenge-response" style of Definition 4.2.1 for a limit statement of the form $\lim_{x \to c}f(x) = \infty$ and use it to prove the previous statement }

\textbf{Definition of limit to infinity}
Let $f : A \to \textbf{R}$, and let $c$ be a limit point of the domain $A$. We say that
$\lim_{x\to c} f(x) = \infty$ provided that, for all $\epsilon \in \textbf{R}$, there exists
a $\delta > 0$ such that whenever $0 < |x - c| < \delta$ (and $x \in A$) it follows
that $f(x) > \epsilon$.

Now we need to show that for  $f(x) = 1/x^2$
$$\lim_{x \to 0}f(x) = \infty$$

First
$$ f(x) > \epsilon$$
$$ \frac{1}{x^2} > \epsilon$$
$$ x^2 < \frac{1}{\epsilon}$$
$$ x < \sqrt{\frac{1}{\epsilon}}$$

therefore if we pick $\delta = \sqrt{\frac{1}{\epsilon}}$, then it follows that
$$ f(x) > \epsilon$$
as desired.

Quick (and insufficient) test in Python seems to corraborate  this statement

\textit{(b) Now construct a definition for the statement $\lim_{x \to \infty} f(x) = L$. Show
$\lim_{x \to \infty} 1/x = 0$}

\textbf{Definition of infinite limit}
Let $f : A \to \textbf{R}$, and let $c$ be a limit point of the domain $A$. We say that
$\lim_{x \to \infty} f(x) = L$ provided that, for all $\epsilon \in \textbf{R} > 0$, there exists
a $\delta$ such that whenever $x > \delta$ (and $x \in A$) it follows
that $|f(x) - c | < \epsilon$.

We start as ususal at the $\epsilon$
$$|f(x) - 0| < \epsilon$$
$$|1/x| < \epsilon$$
Given that we can pick any $\delta$ as we want, we can pick it at the very least at $0$ to get rid
of the absolute value
$$1/x < \epsilon$$
$$x > 1/\epsilon$$

therefore $\delta = 1/\epsilon$ then it follows that $$|f(x) - 0| < \epsilon$$ as desired.

\textit{(c) What would a rigorous definition for $\lim_{x \to \infty} f(x) = \infty$ would look like? Give an example of such a limit}

\textbf{Definition of infinite limit to infinity}
Let $f : A \to \textbf{R}$, and let $c$ be a limit point of the domain $A$. We say that
$\lim_{x \to \infty} f(x) = \infty$ provided that, for all $\epsilon \in \textbf{R}$, there exists
a $\delta$ such that whenever $x > \delta$ (and $x \in A$) it follows
that $f(x) > \epsilon$.

The corresponding example of such a limit  is $f(x) = x$.

\section*{4.2.8}
\textit{Assume $f(x) \geq g(x)$ for all $x$ in some set $A$ on which $f$ and $g$ are defined. Show that for any limit point $c$ of $A$ we must have }
$$\lim_{x \to c} f(x) \geq \lim_{x \to c} g(x) $$

I'm gonna do it by using contradiction; suppose that $f(x)$ and $g(x)$ are defined as in the
exercise, but
$$\lim_{x \to c} f(x) <  \lim_{x \to c} g(x) $$
% for some $c \in A$

% then
% $$\lim_{x \to c} f(x) -  \lim_{x \to c} g(x) < 0 $$

% Let $\lim_{x \to c} f(x) -  \lim_{x \to c} g(x) = M < 0$

% therefore for $\epsilon = 0 - M$ there exist $\delta$ s.t.

% $$|x - c| < \delta \to |f(x) - g(x) + M| < \epsilon = - M$$

% thus 

then it follows that there exist a sequence $(a_n) \to c$ such that $f(a_n) \geq g(a_n)$ for all
$n \in \textbf{N}$; Therefore $\lim(f(a_n)) \geq \lim(g(a_n))$ and  but it contradicts our
initial assumption.

\section*{4.2.9 (Squeeze Theorem)} Let $f,g$ and $h$ satisfy $f(x) \geq g(x) \geq h(x)$ for all
$x$ in some common domain $A$. If $\lim_{x \to c}f(x) = L$ and $\lim_{x \to c}h(x) = L$ at some
limit point $c$ of  $A$, show $\lim_{x \to c}g(x) = L$ as well

As proven in the previous exercise
$$\forall x \in A: f(x) > g(x) \to \lim_{x \to c} f(x) \geq \lim_{x \to c} g(x) $$

therefore

$$\lim_{x \to c} f(x) = L \geq \lim_{x \to c} g(x) $$
and
$$\lim_{x \to c} g(x) \geq \lim_{x \to c} h(x) = L $$
Thus 
$$ L \geq\lim_{x \to c} g(x) \geq L  $$
therefore
$$\lim_{x \to c} g(x) = L  $$
as desired.

\section*{4.3.1}
\textit{Let $g(x) = \sqrt[3]{x}$.}

\textit{(a) Prove that g is continous at c = 0}

We're gonna use $\epsilon-\delta$ definition. First of all, let's state that $g(0) = 0$. Therefore

$$|f(x) - f(c)| = |\sqrt[3]{x} - 0|  < \epsilon $$
$$ |\sqrt[3]{x}| < \epsilon $$

Here I would like to proof that $ \forall x \in \textbf{R}: |\sqrt[3]{x}| = \sqrt[3]{|x|}$: 
if $x \geq 0$ then $|\sqrt[3]{x}| = \sqrt[3]{x}= \sqrt[3]{|x|}$;
if $x < 0$ then $|\sqrt[3]{x}| = \sqrt[3]{-x}= \sqrt[3]{|x|}$. Therefore 
$$ |\sqrt[3]{x}| = \sqrt[3]{|x|} =  < \epsilon $$ is justified.

Therefore we can state that 
$$|x| =  < \epsilon ^ 3$$ 
Thus if we pick $\delta = \epsilon ^ 3$ then
$$|x - c| = |x| < \delta \to |f(x) - f(c)| = |\sqrt[3]{x} - 0| = |\sqrt[3]{x}|
= \sqrt[3]{|x|} < \sqrt[3]{\epsilon^3} =  \epsilon $$

Therefore $g$ is continous at 0

\textit{(b) Prove that $g$ is continous at a point $c \neq 0$. (The identity
  $a^3 - b^3 = (a - b)(a ^ 2 + ab + b^2)$ will be helpful)}

We're gonna use $\epsilon-\delta$ definition once again.
$$|f(x) - f(c)| = |\sqrt[3]{x} - \sqrt[3]{c}| < \epsilon$$
First, let's use a little algebra
$$|\sqrt[3]{x} - \sqrt[3]{c}| = |\sqrt[3]{x} - \sqrt[3]{c}| * 1 =
|\sqrt[3]{x} - \sqrt[3]{c}|\frac{(\sqrt[3]{x}^2 + \sqrt[3]{x}\sqrt[3]{c} +
  \sqrt[3]{c} ^ 2)}{(\sqrt[3]{x}^2 + \sqrt[3]{x}\sqrt[3]{c}
  + \sqrt[3]{c} ^ 2)} = \frac{|\sqrt[3]{x} - \sqrt[3]{c}|(\sqrt[3]{x}^2 + \sqrt[3]{x}\sqrt[3]{c} +
  \sqrt[3]{c} ^ 2)}{(\sqrt[3]{x}^2 + \sqrt[3]{x}\sqrt[3]{c}
  + \sqrt[3]{c} ^ 2)}$$

Let's look now at the sum  $\sqrt[3]{x} ^ 2 + \sqrt[3]{x}\sqrt[3]{c} +
\sqrt[3]{c}^2$: $\sqrt[3]{x} ^ 2 \geq 0 $ because it is a square. For
$\sqrt[3]{x} + \sqrt[3]{x} ^ 2$ we need to be able to articulate $\delta$ so
that both $x$ and $c$ are the same sign; if we fo that then it becomes
nonnegative. $\sqrt[3]{c} ^ 2 \geq 0 $ because it is a square

Therefore if right now we pinky-promise that we will account for unusual delta
in the future, then we are able to say that 
$$\sqrt[3]{x} ^ 2 + \sqrt[3]{x}\sqrt[3]{c} + \sqrt[3]{c}^2 \geq 0 $$
And therefore
$$\sqrt[3]{x} ^ 2 + \sqrt[3]{x}\sqrt[3]{c} + \sqrt[3]{c}^2 =
|\sqrt[3]{x} ^ 2 + \sqrt[3]{x}\sqrt[3]{c} + \sqrt[3]{c}^2| $$

Continuing with our initial algebra

$$\frac{|\sqrt[3]{x} - \sqrt[3]{c}|(\sqrt[3]{x}^2 + \sqrt[3]{x}\sqrt[3]{c} +
  \sqrt[3]{c} ^ 2)}{(\sqrt[3]{x}^2 + \sqrt[3]{x}\sqrt[3]{c}
  + \sqrt[3]{c} ^ 2)} =
\frac{|\sqrt[3]{x} - \sqrt[3]{c}||\sqrt[3]{x}^2 + \sqrt[3]{x}\sqrt[3]{c} +
  \sqrt[3]{c} ^ 2|}{(\sqrt[3]{x}^2 + \sqrt[3]{x}\sqrt[3]{c}
  + \sqrt[3]{c} ^ 2)} =
\frac{|x - c|}{(\sqrt[3]{x}^2 + \sqrt[3]{x}\sqrt[3]{c}
  + \sqrt[3]{c} ^ 2)} =
$$
$$ |x - c|\frac{1}{(\sqrt[3]{x}^2 + \sqrt[3]{x}\sqrt[3]{c}
  + \sqrt[3]{c} ^ 2)} < \epsilon
$$
As we disussed earlier $(\sqrt[3]{x}^2 + \sqrt[3]{x}\sqrt[3]{c}  +
\sqrt[3]{c} ^ 2) \geq 0$ and therefore 

$$ |x - c| < \epsilon(\sqrt[3]{x}^2 + \sqrt[3]{x}\sqrt[3]{c}
+ \sqrt[3]{c} ^ 2) $$

Thus, if we pick $\delta = min\{\epsilon(\sqrt[3]{x}^2 + \sqrt[3]{x}\sqrt[3]{c}
+ \sqrt[3]{c} ^ 2), |x - 0|\}$ (we need the second value
because we need the sum to be equal to its absolute value; ) then

$$|x - c| < \delta \to |f(x)  - f(c)| < \epsilon$$

Therefore $f(x) = \sqrt[3]{x}$ is continous on \textbf{R}.

\section*{4.3.2}

\textit{(a) Supply a proof for Theorem 4.3.9 using the $\epsilon-\delta$
  characterization of continuity.}

First, let's state the theorem

\textbf{Theorem 4.3.9 (Composition of Continuous Functions).} \textit{Given
  $f: A \to \textbf{R}$ and $g: B \to \textbf{R}$, assume that the range
  $f(A) =\{f(x): x \in A\}$ is contained in the domain $B$ so that the
  composition $g \circ f = g(f(x)) $ is well-defined on $A$. }

\textit{If $f$ is continous ac $c \in A$, and if $g$ is continous at
  $f(c) \in B$, then $g \circ f$ is continous at c.}

Firstly, the fact that both $f$ and $g$ are continous tells that

$$\forall \epsilon_1 \in \textbf{R}: \exists \delta_1:  |x - c| < \delta_1 \to
|f(x) - f(c)| < \epsilon_1$$
$$\forall \epsilon_2 \in \textbf{R}: \exists \delta_2: |x - c| < \delta_2 \to
|g(x) - g (c)| < \epsilon_2$$
And we need to prove that
$$\forall \epsilon \in \textbf{R}: \exists \delta: |x - c| < \delta \to
|g(f(x)) - g (f(c))| < \epsilon$$

% Let's pick the $c \in A$. 
% Firstly, because of all of the continuity and stuff, we are assured, that there
% exists partucular $M=g(f(c))$. Let's fix $\epsilon$. Therefore if
% we plug this $\epsilon$ into continuity of $g(x)$, then we'll get $\delta_1$.

The main strategy for this one is to plug some delta into some epsilon (or
vice versa), and get some use out of it.

Firstly, let's get some things out of the way: let us fix particular $c \in A$
and $\epsilon \in \textbf{R} > 0$. Then, let's plug this $\epsilon$ at $f(c)$
into the continuity of $g(x)$ so we can get a $\delta_g > 0$. Therefore
we will have
$$ \forall \epsilon \in \textbf{R}: \exists \delta_g: |x - f(c)| < \delta_g
\to |g(x) - g(f(c))| < \epsilon $$
which is kinda close to the thing, that we're trying to prove.

We also know that
$$ \forall \epsilon_f \in \textbf{R}: \exists \delta_f: |x - c | < \delta_f:
|f(x) - f(c)| < \epsilon_f$$
therefore it is true that
$$ \forall \epsilon \in \textbf{R}: \exists \delta_g: |y - f(c)| < \delta_g
\to |g(y) - g(f(c))| < \epsilon $$
$$ \exists \delta_f: |x - c | < \delta_f \to
|f(x) - f(c)| < \delta_g$$

From this we can state that
$$ \forall \epsilon \in \textbf{R} > 0: \exists \delta_f: |x - c | < \delta_f \to |f(x) - f(c)| < \delta_g \to
|g(f(x)) - g(f(c))| < \epsilon $$

This doesn't sound too persuasive for me, so I probably need to explore it a
little but more.

Suppose that with all the present assumptions, we get the given $\epsilon$.
If we plug it into definition of continuity for  $g(x)$ at $g(f(c))$, then
we'll get the neccesary $\delta_g$. If we plug $\delta_g$ as an $\epsilon$
for the definition of continuity of $f(x)$, then we'll get $\delta_f$.

We can probably prove it with a little bit more clarity. We need to prove that
$$\forall \epsilon \in \textbf{R}: \exists \delta: |x - f(c)| < \delta \to
|g(f(x)) - g (f(c))| < \epsilon$$

Firstly, definition of contonuity of $g(x)$ gives us the fact, that 
$$ \forall \epsilon \in \textbf{R}: \exists \delta_g: |x - f(c)| < \delta_g
\to |g(x) - g(f(c))| < \epsilon $$

then if $x \in f(A)$ then $\exists y \in A $ s.t. $f(y) = x$ therefore
$$ \forall \epsilon \in \textbf{R}: \exists \delta_g: |f(y) - f(c)| < \delta_g
\to |g(f(y)) - g(f(c))| < \epsilon $$

From the definition of continuity of $f$ we know that 

$$ \forall \epsilon_f \in \textbf{R}: \exists \delta_f: |x - c | < \delta_f:
|f(x) - f(c)| < \epsilon_f$$

Therefore 
$$\forall \epsilon \in \textbf{R}: \exists \delta: |x - f(c)| < \delta \to
|g(f(x)) - g (f(c))| < \epsilon$$
as desired.

\textit{(b) Give another proof of this theorem using the sequantial
  characterization of continuity (from Theorem 4.3.2 (iv)) }

Theorem 4.3.2 (iv) states that if $(x_n) \to c$ (with $x_n \in A$), then
$f(x_n) \to f(c)$.

Because $f(x)$ is continous we can state that for every sequence $(x_n) \to c$
it is true that $f(x_n) \to f(c)$. Therefore because $f(x_n)$ is a sequence
itself, we can state that $g(f(x_n)) \to g(f(c))$. Therefore it is true, that
for every sequence $(x_n) \to c$ it follows, that $g(f(x_n)) \to g(f(c))$.
Therefore $g(f(x))$ is continous, as desired.

\section*{4.3.3}
\textit{Using the $\epsilon-\delta$ characteriation of continuity (and tus using no previous results anbout the sequences), show that the linear function $f(x) = ax + b$ is continous at every poinnt of \textbf{R}.}

Let's start with our usual stuff

$$ |f(x) - f(c)| < \epsilon $$
$$ |ax + b - (ac + b)| = |ax + b - ac - b| = |a||x - c| < \epsilon $$
$$|x - c| < \epsilon / a $$

Therefore if we pick $\delta = \epsilon / a$ then it follows that $|f(x) - f(c)| < \epsilon$, as desired.

\section*{4.3.4}
\textit{(a) Show using Definition 4.3.1 that any function $f$ with domain
  \textbf{Z} with necessarily be continous at every point in its domain.}

Suppose that $f: Z \to R$. We need to prove that 

$$\forall \epsilon: \exists \delta: |x - c| < \delta \to |f(x) - f(c)| < \epsilon $$

Suppose that we pick $\delta = 0.1$ (or any other value, such that the only one
of the domain values will be in the needed neighborhood). Then there will be
only one number in the domain neighhborhood, and because of that we can state
that
$$|f(x) - f(c)| = |f(c) - f(c)|  = 0 < \epsilon$$

Therefore the fucntion is continous, as desired.

\textit{(b) Show in general that if $c$ is an isolated point of $A \subseteq \textbf{R}$, then $f: A \to \textbf{R}$ is continous at c.}

In this particular case we can't just set $\delta$ at some number, so we gotta
be a little more creative. To be distract myself from getting any unproductive
ideas, I should state here that $\textbf{Q}$ is a set of isolated points.

To be continued

\section*{3.2.1}
\textit{(a) Where in the proof of Theorem 3.2.3 part (ii) does the assumption
  that the collection of open sets be finite get used}

Theorem 3.2.3 states that

(ii) The intersection of a finite collection of open sets is open.

The assumption of the finality of the set is used in the fact, that we need
the minimum of the epsilons.

\textit{(b) Give an example of an infinite collection of nested open sets}
$$ O_1 \supseteq O_2 \supseteq O_3 \supseteq O_4 \supseteq ... $$
\textit{whose intersection $\cap_{n = 1}^{\infty} O_n$ is closed and nonempty.}

First of all, we should state that open is not an opposite of closed in this
context. We can get $O_n = (-\infty; \infty)$. Then this definition
(technically) fits into the requrement of qs

Let $O_n = (1 - 1/n, 2 + 1/n)$. Let us also define 
$$A = \cap_{n = 1}^{\infty} O_n$$

Suppose that $x \in A$. To be continued...


\section*{1.2.1}
\textit{(a) Prove that $\sqrt{3}$ is irrational. Does a simular argument work
  to show $\sqrt{6}$ is irrational?}

Suppose that $\sqrt{3}$ is a rational number; then it is true that
$$\exists m \in \textbf{Z}, n \in \textbf{N}: \frac{m}{n} = \sqrt{3}$$
where $m$ and $n$ are at their lowest possible terms. Then
$$\sqrt{3}n = m$$
$$3n^2 = m^2$$

Therefore we can state, that $m \% 3 = 0$. Therefore $\exists k: 3k = m$.
Thus we can reformulate formula as
$$3n^2 = (3k)^2$$
$$n^2 = 3k^2$$

Therefore $n\%3 = 0$ as well. Therefore $n$ and $k$ are not in their possible
terms, which conradicts our initial assumtions. Therefore we can state that
$\sqrt{3} \notin \textbf{Q}$.

Let's try the same argument for $\sqrt{6}$.
$$\exists m \in \textbf{Z}, n \in \textbf{N}: \frac{m}{n} = \sqrt{6}$$
$$\sqrt{6}n = m$$
$$6n^2 = m^2$$
then m has as their dividers both 2 and 3. Therefore $m\%2 = 0$ and $m\%3 = 0$.
Therefore we can proceed with the same argument as earlier
$$6n^2 = (6k)^2$$
$$n^2 = 6k^2$$

Therefore n is divided by 6, etc., etc., $\sqrt{6} \notin \textbf{Q}$.

\textit{(b) Where does the proof of Theorem 1.1.1 break down if we try to use
  it to prove $\sqrt{4}$ is irrational? }

Suppose that $\sqrt{4}$ is a rational number; then it is true that
$$\exists m \in \textbf{Z}, n \in \textbf{N}: \frac{m}{n} = \sqrt{2}$$
where $m$ and $n$ are at their lowest possible terms. Then
$$\sqrt{4}n = m$$
$$4n^2 = m^2$$

n can still be odd and m can still be even. In other words, m is divisible by
a prime, and the number under the radical consists of two primes. Therefore
if a number decomposes to two equal sets of primes, then its square root is
a rational number. Otherwise it isn't.

\section*{1.2.2}

\textit{Decide which of the following represent true statements about the
  nature of sets. For any that are false, provide a specific exapmple where the
  statement in question does not hold.}

\textit{(a) if $A_1 \supseteq A_2 \supseteq A_3 \supseteq ... $ are all sets
  containing an infinite number of elements, then the intersection
  $\cap_{n = 1}^{\infty} A_n$ is infinite as well.} -

$\cap_{n = 1}^{\infty} A_n = (0, 1/n)$ has no numbers in it.

Proof is easy -

$$\forall x \in \textbf{R} > 0: \exists n \in N: 1/n < x$$

\textit{(b) if $A_1 \supseteq A_2 \supseteq A_3 \supseteq ... $ are all finite,
  nonempty sets of real numbers, then the intersection
  $\cap_{n = 1}^{\infty} A_n$ is finite and nonempty.} -

True.

There is no need for the proof, but I'll supply one anyways. If all $A_n$ are
finite and nonempty, then $\exists j \in \textbf{N} : |A_1| = j$. Therefore,
because of the same reasons, there are only $j - 1$ times when

$$A_k \supset A_{k + 1}$$

can happen, because after $j - 1$ times the set will be empty. Therefore,
because it is finite, their intersection will have finite number of
elements and will be non-empty.

\textit{(c) $A \cap (B \cup C) = (A \cap B) \cup C$}

False: let

$$x \notin A, x \notin B, x \in C$$
Then
$$x \in A \cap (B \cup C); x \notin = (A \cap B) \cup C$$

\textit{(c) $A \cap (B \cap C) = (A \cap B) \cap C$}

True. Kinda goes without a proof; if you imagine a Vien diagram, then it's
obvious.

\textit{(c) $A \cap (B \cup C) = (A \cap B)  \cup (A \cap C)$}

True. For the same reason as before.

I'm sure that there exist more concrete versions of those proofs, but I'm not
required to provide any. My suspition on why is it so, is because it's a
little more complicated and requires more knowlege in set theory and/or logic.

\section*{1.2.3 (De Morgan's Laws).}

\textit{Let A and B be subsets of \textbf{R}}

\textit{(a) If $x \in (A \cap B)^c$, explain why $x \in A^c \cup B^c$. This
  shows that $(A \cap B)^c \subseteq (A \cap B)^c$.}

If we have two sets $A$ and $B$, then \textbf{R} desintegrates into 4 different
sets: $A$, $B$, $A^c$, $B^c$.

Therefore there must exists sets
$$S_1 = A \cap B$$
$$S_2 = A^c \cap B$$
$$S_3 = A \cap B^c$$
$$S_4 = A^c \cap B^c$$

An element cannot be in the set and not in the set at the same time. Therefore,
there does not exist an element, which is in two of $S_n$'s.

For any $x \in \textbf{R} \to x \in A$ or $x \notin A$. Therefore an element
of $\textbf{R}$ needs to be in at least one of those sets. It is easily seen by
$$A \cap \textbf{R} = A$$
$$A \cap (B \cup B^c) = A$$
$$(A \cap B) \cup (A \cap B^c)) = A$$

Therefore $\cup_{n = 1}^4 S_n = \textbf{R}$ and
$\cap_{n = 1}^4 S_n = \emptyset$.

Suppose $x \in (A \cap B)^c$. Then $x \notin A \cap B$. Therefore
$x \in S_2 \cup S_3 \cup S_4$.

Suppose that $x \in A^c \cup B^c$. Then $x \in S_2 \cup S_3 \cup S_4$.

Therefore $ (A \cap B)^c \subseteq A^c \cup B^c$.

\textit{(b) Prove the reverse inclusion}


As seen in part (a)

$$(A \cap B)^c = S_2 \cup S_3 \cup S_4 = A^c \cup B^c$$

\textit{(c) Show $(A \cup B)^c = A^c \cap B^c$ by demonstrating inclusion both
  ways.}

No need to do both ways.
$$(A \cup B)^c = S_4 = A^c \cap B^c$$


\section*{1.2.4}
\textit{Verify the triangle inequality in the special cases where }

\textit{(a) $a$ and $b$ have the same sign}

Suppose $a \geq 0$, $b \geq 0$. Then $|a| = a$ and $|b| = b$. Therefore
$$|a + b| = a + b = |a| + |b| \leq  |a| + |b|$$

Suppose $a < 0$, $b < 0$. Then $|a| = -a$ and $|b| = -b$; also $a + b < 0 \to
|a + b| = -(a + b) = -a - b$. Therefore 
$$|a + b| = -a + (-b) = |a| + |b| \leq  |a| + |b|$$.

\textit{(b) $a \geq 0$, $b < 0$ and $a + b \geq 0$.}

$$a + b \geq 0 \to a + b = |a + b|$$

Also, $|a| = a$ and $|b| = -b$. Therefore
$$a + b \geq 0 \to a \geq -b \to a \geq |b| \to |a| \geq |b|$$

$$ b < 0$$
$$ b \leq 0$$
$$ 2b \leq 0$$
$$ b + b \leq 0$$
$$ b \leq (-b)$$
$$a + b \leq a + (-b)$$
$$|a + b| \leq |a| + |b|$$

\section*{1.2.5}
\textit{Use the triangle inequality ti establish the inequalities}

\textit{(a) $|a - b| \leq |a| + |b|;$}
$$|a - b| = |a + (-b)| \leq |a| + |-b| = |a| + |b|$$

\textit{(b) $||a| - |b|| \leq |a - b|$;}

let $a = a + b - b$. Then

$$|a| = |a - b + b| \leq |a - b| + |b|$$
$$|a| - |b| \leq |a - b|$$
$$|b| = |b - a + a| \leq |b - a| + |a| = |a - b| + |a|$$
$$|b| - |a| \leq |a - b|$$
$$|a| - |b| \geq -|a - b|$$
$$-|a - b| \leq |a| - |b| \leq |a - b| \to ||a| - |b|| \leq |a - b|$$

\section*{1.2.6}
\textit{Given a function $f$ and a subset $A$ of its domain, let $f(A)$
  represent the range of $f$ over the set $A$; that is,
  $f(A) = \{f(x): x \in A\}$. }

\textit{(a) Let $f(x) = x^2$. if $A=[0,2]$ (the closed interval $\{x \in
  \textbf{R}: 0 \leq x \leq 2\}$) and $B=[1,4]$, find $f(A)$ and $f(B)$. Does
  $f (A \cap B) = f(A) \cap f(B)$ in this case? Does $f(A \cup B) = f(A) \cup
  f(B)$? }

First things first: $f(A) = [0, 4]$; $f(B) = [1, 16]$ (without any proof
because if we don't go with axiomatic stuff, then it is obvious).

$$f(A \cap B) = f([1, 2]) = [1, 4]$$
$$f(A) \cap f(B) = [1, 4]$$

Therefore in this case $f(A) \cap f(B) = f(A \cap B)$.

$$f(A \cup B) = f([0, 4]) = [0, 16] = f(A) \cup f(B)$$

\textit{(b) Find two sets $A$ and $B$ for which $f(A \cap B) \neq f(A) \cap f(B)$.}

Let $A = [-1, 0]$ and $B = [0, 1]$. Then
$$f(A \cap B) = f(\{0\}) = \{0\}$$
$$f(A) \cap f(B) = [0, 1] \cap [0, 1] = [0, 1] \neq f(A \cap B)$$

\textit{(c) Show that, for an arbitrary function $g: \textbf{R} \to \textbf{R}$, it
  is always true that $g(A \cap B) \subseteq g(A) \cap g(B)$ for all sets
  $A,B \subseteq \textbf{R}$.}

$$x \in g(A \cap B) \to x \in g(A)$$
$$x \in g(A \cap B) \to x \in g(B)$$
Therefore
$$x \in g(A \cap B) \to x \in g(A) \cap g(B)$$
Thus
$$g(A \cap B) \subseteq g(A) \cap g(B)$$

\textit{(d) Form and prove a conjecture aout the relationship between $g(A \cup B)$ and $g(A) \cup g(B)$ for an arbitrary function $g$.}

$$x \in g(A) \to x \in g(A \cup B)$$
$$x \in g(B) \to x \in g(A \cup B)$$

Therefore
$$x \in g(A) \cup g(B) \to x \in g(A \cup B)$$
Thus
$$g(A) \cup g(B) \subseteq g(A \cup B)$$

Suppose that

$$\exists y \in \textbf{R}: y \in g(A \cup B); y \notin g(A) \cup g(B)$$

Then $\exists q_1 \in A \cup B: g(q_1) = y$ but
$$\forall q_2 \in A, q_3 \in B: g(q_2) \neq y; g(q_3) \neq y$$

Therefore $q_1 \notin A$ and $q_1 \notin B$. Therefore $q_1 \in A^c \cap B^c$.
Using De Morgan rule
$$q_1 \in A^c \cap B^c \to q_1 \in (A \cup B)^c$$
therefore 
$$q_1 \notin g(A \cup B)$$
which is a contradiction. Therefore

$$y \in g(A \cup B) \to g(A) \cup g(B)$$
Thus
$$g(A \cup B) \subseteq g(A) \cup g(B)$$

Therefore if we take into account previous conclusion

$$g(A \cup B) = g(A) \cup g(B)$$

for any $g$.

\section*{1.2.7}

\textit{Given a function $f: D \to \textbf{R}$ and a subset $B \subseteq \textbf{R}$, let $f^{-1}(B)$ be the set of all points from the domain $D$ that get mapped into $B$; that is, $f^{-1}(B) = \{x \in D: f(x) \in B\}$. This is called
  the preimage of $B$.}

\textit{(a) Let $f(x) = x^2$. If A is the closed interval $[0,4]$ and B is the
  closed interval $[-1, 1]$, find $f^{-1}(A)$ and $f^{-1}(B)$. Does
  $f^{-1}(A \cap B) = f^{-1}(A) \cap f^{-1}(B)$ in this case? Does
  $f^{-1}(A \cup B) = f^{-1}(A) \cup f^{-1}(B)$?
}

$$f^{-1}(A) = [-2, 2]$$
$$f^{-1}(B) = [-1, 1]$$
$$f^{-1}(A \cap B) = f^{-1}([0, 1]) = [-1, 1] = f^{-1}(A) \cap f^{-1}(B)$$
$$f^{-1}(A \cup B) = f^{-1}([-1, 4]) = [-2, 2] = f^{-1}(A) \cup f^{-1}(B)$$

\textit{(b) The good behaviour of preimages demonstated in (a) is completely
  general. Show that for an arbitrary function $g: \textbf{R} \to \textbf{R}$,
  it is always true that $g^{-1}(A \cap B) = g^{-1}(A) \cap g^{-1}(B)$ and
  $g^{-1}(A \cup B) = g^{-1}(A) \cup g^{-1}(B)$ for all sets $A, B \subseteq \textbf{R}$.
}

% $$ x_1 \in g^{-1}(A) \to \exists y_1 \in A: g(y) = x$$
% $$ x_2 \in g^{-1}(B) \to \exists y_2 \in B: g(y) = x$$
By definition
$$ x \in g^{-1}(A \cap B) \to \exists y \in A \cap B: y = g(x)$$
Therefore if we we use the fact  $y \in A \cap B \to y \in A$ and $y \in A \cap B \to y \in B$
$$ x \in g^{-1}(A \cap B) \to \exists y \in A: y = g(x) \to x \in g^{-1}(A)$$
$$ x \in g^{-1}(A \cap B) \to \exists y \in B: y = g(x) \to x \in g^{-1}(B)$$
therefore $x \in g^{-1}(A \cap B)$ implies that $x \in g^{-1}(A)$ and $x \in g^{-1}(B)$, or in other words
$$g^{-1}(A \cap B) \subseteq g^{-1}(A) \cap g^{-1}(B)$$

In other direction: 
$$x \in g^{-1}(A) \to \exists y_1 \in A: y_1 = g(x)$$
$$x \in g^{-1}(B) \to \exists y_2 \in B: y_2 = g(x)$$

$x \in g^{-1}(A) \cap g^{-1}(B)$ implies that $ \exists y_1 \in A: g(x) = y_1$ and $\exists y_2 \in B: y_2 = g(x)$. Because $g$ is a function we know, that
for every $x$ there exists only one $y = g(x)$. Therefore $y_1 = y_2 = g(x)$.
Thus we can state that $y \in A \cap B$.

thus
$$x \in g^{-1}(A) \cap g^{-1}(B) \to \exists y \in A \cap B: y = g(x) \to
x \in g^{-1}(A \cap B)$$

Therefore 

$$ g^{-1}(A) \cap g^{-1}(B) \subseteq   g^{-1}(A \cap B)$$

If we take previous conclusion into account, then it follows that
$$ g^{-1}(A) \cap g^{-1}(B) = g^{-1}(A \cap B)$$
as desired.

Now let's prove that  $g^{-1}(A \cup B) = g^{-1}(A) \cup g^{-1}(B)$:


If $ x \in g^{-1}(A) \cup g^{-1}(B))$ then  $\exists y \in A: y = g(x)$ or
$\exists y \in B: y = g(x)$. If we take into account that $y \in A \to y \in A \cup B$ then we can conclude that

$$ x \in g^{-1}(A) \cup g^{-1}(B)) \to \exists y \in A \cup B : y = g(x) \to
x \in g^{-1}(A \cup B)$$
Thus

$$g^{-1}(A) \cup g^{-1}(B) \subseteq g^{-1}(A \cup B)$$

In other direction: 
$$x \in g^{-1}(A \cup B) \to \exists y \in A \cup B: y = g(x) \to y = g(x)$$

As proven before $g(A \cup B) = g(A) \cup g(B)$ and therefore
$y \in g(A \cup B)$ implies that either $y \in g(A)$ or $y \in g(B)$. Therefore
$$ x \in g^{-1}(A \cup B) \to x \in g^{-1}(A) \cup g^{-1}(B)$$
$$ g^{-1}(A \cup B)  \subseteq g^{-1}(A) \cup g^{-1}(B)$$
And if we combine this fact with previous conclusion:
$$ g^{-1}(A \cup B) =  g^{-1}(A) \cup g^{-1}(B)$$
as desired.

\section*{1.2.8}

\textit{Form the logical negation of each claim. One way to do this is to
  simply add "It is bot the case that ... " in front of each assertion, but for
  each statement, try to embed the word "not" as deeply into the resulting
  sentence as possible (or avoid using it altogether).}

\textit{(a) For all real numbers satisfying $a < b$, there exist an $n \in
  \textbf{N}$ such that $a + 1/n < b$.}
There exist real numbers $a < b$ such that $a + 1/n \geq b$ for all $n \in \textbf{N}$.

\textit{(b) Between every two distinct real numbers, there is a rational number}

There exist two real numbers, such that there are only irrational numbers
between them.

\textit{(c) For all natural numbers $n \in \textbf{N}$, $\sqrt{n}$ is either a
  natural number  or an irrational number}

There exist a natural number $n \in \textbf{N}$, such that $\sqrt{n}$ is a
rational number, that is not a natural number. (This one is a little bit weird
if we try to negate this, but "not" is stuffed as deep as possible)

\textit{(d) Given any real number $x \in \textbf{R}$, there exist $n \in
  \textbf{N}$ satistying $n > x$}

There exist a real number $x \in \textbf{R}$, such that for all $n \in \textbf{N}$ it is true that $n \leq x$.

\section*{1.2.9}
\textit{Show that the sequence $(x_1, x_2, x_3,...)$ defined in Example 1.2.7
  is bounded above by 2; that is, prove that $x_n \leq 2$ for every $n \in
  \textbf{N}$.}

The mentioned sequence is defined by
$$x_1 = 1$$
$$x_{n + 1} = (1/2)x_n + 1$$

A great advice about induction states, that when you hear words "prove" and
"sequence" in the same sentence, then the word "recursion" should pop up in
your head. So here we go

Base case: $x_1 \leq 2$.

Inductive proposition: $x_n \leq 2$

Inductive step:
$$x_n \leq 2$$
$$(1/2)x_n \leq 1$$
$$(1/2)x_n + 1 \leq 2$$
$$x_{n + 1} = (1/2)x_n + 1 \leq 2$$
$$x_{n + 1} \leq 2$$
as desired.

\section*{1.2.10}
\textit{Let $y_1 = 1$, and for each $n \in \textbf{N}$ define $y_{n + 1} =
  (3 * y_n + 4) / 4$.}

\textit{(a) Use induction to prove that the sequence satisfies $y_n < 4$ for
  all $n \in \textbf{N}$.}

Base case: $y_1 = 1 < 4$

Inductive proposition: $y_n < 4$

Inductive step:

$$y_n < 4$$
$$3 * y_n < 12$$
$$3 * y_n + 4 < 16$$
$$(3 * y_n + 4) / 4 < 4$$
$$y_{n + 1} =  (3 * y_n + 4) / 4 < 4$$
$$y_{n + 1} < 4$$
as desired.

\textit{(b) Use another induction to show the sequence $(y_1, y_2, y_3,...)$
  is increasing}

We need to show that $y_{n + 1} - y_n \geq 0$

As shown earlier 
$$y_n < 4$$
therefore
$$ y_n < 4$$
$$ \frac{y_n}{4} < 1$$
$$1 > \frac{y_n}{4}$$
$$1 - \frac{y_n}{4} > 0$$
$$1 + (\frac{3 y_n}{4} - y_n) > 0$$
$$\frac{3 y_n}{4} + 1 - y_n > 0$$
$$(3 * y_n + 4) / 4 - y_n  > 0$$
$$y_{n + 1} - y_n  > 0$$
as desired.

\section*{1.2.11}
\textit{If a set $A$ contains $n$ elements, prove that the number of
  different subsets of $A$ is equal to $2^n$. (Keep in mind that the empty set
  $\emptyset$ is considered to be a subset of every set.)}

This proof is dumb, but intuitive:

Every subset is corresponding to a number in binary number: 0 for excluded,
1 for included. Therefore there exist $2^n$ possible combinations.

For a more concrete proof let's resort to induction.

Base case(s): subsets of $\emptyset$ are $\emptyset$ itseft ($2^0 = 1$ in total). Subsets of
set with one element are $\emptyset$ and set itself ($2^1 = 1$ in total).

Proposition is that set with n elements has $2^n$ subsets.

Inductive step is that for set with $n + 1$ elements can either have or hot
have the $n + 1$'th element. Therefore there exist $2^n + 2^n = 2 * 2^n =
2^{n + 1}$ subsets, as desired.

\section*{1.2.12}
\textit{For this exerice, assume Exercise 1.2.3 has been successfully completed
  (as it was)}

\textit{(a) Show how induction can be used to conclude that }
$$ (A_1 \cup A_2 \cup ... \cup A_n) = A^c_1 \cap A^c_2 \cap ... \cap A^c_n$$

First of all, base case

$$ (A_1 \cup A_2)^c = A^c_1 \cap A^c_2 $$

Proposition
$$ (A_1 \cup A_2 \cup ... \cup A_n) = A^c_1 \cap A^c_2 \cap ... \cap A^c_n$$

Step
$$ (A_1 \cup A_2 \cup ... \cup A_n \cup A_{n + 1}) = A^c_1 \cap A^c_2 \cap ... \cap A^c_n \cap A^c_{n + 1}$$

Let us denote $Q = A^c_1 \cap A^c_2 \cap ... \cap A^c_n$. Then by inductive
proposition

$$  A^c_1 \cap A^c_2 \cap ... \cap A^c_n \cap A^c_{n + 1} = Q \cap A^c_{n + 1}
= (Q^c \cup A_{n + 1}) = (A_1 \cup A_2 \cup ... \cup A_n \cup A_{n + 1})
$$
as desired.

\textit{(b) Explain why induction cannot be used to conclude }
$$(\cup^{\infty}_{n = 1}A_n)^c = \cap^{\infty}_{n = 1}A^c_n$$
\textit{It might be useful to consider part (a) of Exercise 1.2.2.}

Induction cannot be used on this one, because for induction we need finite
set of elements. This stands on the fact, that if induction works for
some case, then it works for $n - 1$'th element, and for $n - 2$'th element
and this way all the way down to the base case. As an example of why it doesn't
work, we can take into accound exercise 1.2.2, where all of the elements have
infinite number of elements, and their intersection would have infinite amount
of elements  for any finite number of elements, but it is not true for the
infinite amount.

\textit{(c) Is the statement in part (b) valid? If so, write a proof that does
  not use induction.}

Suppose that
$$x \in (U^{\infty}_{n = 1}A_n)^c$$

Then $x \notin A_n$ for every $n \in \textbf{N}$. Therefore $x \in A^c_n$ for every $n \in \textbf{N}$. Therefore $x \in \cap^{\infty}_{n = 1}A^c_n$. Thus

$$(\cup^{\infty}_{n = 1}A_n)^c \subseteq \cap^{\infty}_{n = 1}A^c_n$$

Suppose that $x \in \cap^{\infty}_{n = 1}A^c_n$. Then $x \notin A_n$ for every $n \in \textbf{N}$. Therefore $x \notin (U^{\infty}_{n = 1}A_n)$ for every $n \in \textbf{N}$. Therefore $x in \cup^{\infty}_{n = 1}A_n)^c$ for every $n \in \textbf{N}$. Therefore
$$ \cap^{\infty}_{n = 1}A^c_n \subseteq  (\cup^{\infty}_{n = 1}A_n)^c$$

Thus if we combine two statements
$$(\cup^{\infty}_{n = 1}A_n)^c = \cap^{\infty}_{n = 1}A^c_n$$
as desired.

\section*{1.3.1}
\textit{Let $\textbf{Z}_5 = \{0, 1, 2, 3, 4, 5\}$ and define addition and
  multiplication modulo 5. In other words, compute the integer remainder when
  $a + b$ and $ab$ are divided by 5, and use this as the value for the sum and
  product, respectively.}

\textit{(a) Show that, given any element $z \neq 0$ in $\textbf{Z}_5$, there
  existsan element $y$ such that $z + y = 0$. The element $y$ is called the
  additive inverse of $z$.}

It is true, that for every of those elements we can set $y = 5 - z$, for which
it is true that $z + y = 5$ and $(z + y)\%5 = 0$ as desired.

\textit{(b) Show that, given any element $z \neq 0$ in $\textbf{Z}_5$, there
  existsan element $x$ such that $zx = 1$. The element $x$ is called the
  multiplicative inverse of $z$.}

$$ (1 * 1) \% 5 = 1 $$
$$ (2 * 3) \% 5 = 1 $$
$$ (3 * 2) \% 5 = 1 $$
$$ (4 * 4) \% 5 = 1 $$
as desired.

\textit{(c) The existence of additive and multiplicative inverses is part of
  the definition of a field. Investigate the set $\textbf{Z}_4 = \{0, 1, 2,
  3\}$ (where addition and multiplication are defined modulo 4) for the
  existense of additive and multiplicative inverses. Make a conjecture about
  the values of n for which additive inverses exist in $\textbf{Z}_n$, and then
  form another conjecture about the existence of multiplicative inverses.}

For $\textbf{Z}_4$ we define additive inverse the same way we defined it
in the  part (a) ($4 - z = y$). For multiplicative inverse we have the way
with $1$, but any for 2 we don't have multiplicative inverse.

Therefore the conjecture about the additive inserse is that every $Z_n$ with
addition defined as addition modulo n we have additive inverse.

Proof of it is that every element of $\textbf{Z}_n$  is less than n, and that
because of this there exists $s = n - x \in \textbf{Z}_n$

For multiplicative inverse the conjecture is that it exists only when
n is a prime number.

\section*{1.3.2}
\textit{(a) Write a formal definition in the style of Definition 1.3.2 for the
  infinum or greatest lower bound of a set}

A real number $s$ is the \textit{greatest lower bound} for a set
$A \subseteq \textbf{R}$ if it meets the following two criteria:

(i) $s$ is a lower bound

(ii) if $b$ is any lower bound for $A$, then $s \geq b$.

\textit{(b) Now, state and prove a version of Lemma 1.3.7 for greatest lower
  bounds.}

\textbf{Lemma for greatest lower bounds}

Assume $s \in \textbf{R}$ is a lower bound for a set  $A \subseteq \textbf{R}$.
Then, $s = inf(A)$ if and only if, for every choice of $\epsilon > 0$, there
exists an element $a \in A$ satisfying $s + \epsilon > a$.

Proof:

In one direction: Suppose $s = inf(A)$. Then, by definition of greatest lower
bound, there does not exist a lower bound, greater than $s$. In other words,
suppose that there exist $\epsilon > 0$ such that there is no element $a \in A$
such that $a < s + \epsilon$. Then $s + \epsilon$ is a lower bound, which is
greater than s, therefore s is not a greatest lower bound, which is a
contradiction. Therefore there does not exist $\epsilon > 0$ for which
there exist no $a \in A$ such that $a < s + \epsilon$. Therefore for
every $\epsilon > 0$ there exist an $a \in A$  such that $a < s + \epsilon$,
as desired.

In other direction: suppose that $s$ is a lower bound and for every $\epsilon
> 0$ there exist $a \in A$ such that $a < s + \epsilon$. Then any number
$s + \epsilon$ is not a lower bound. Therefore any number, which is greater
than $s$ is not a lower bound. Therefore any lower bound is less or equal to
$s$. Therefore $s$ is a greatest lower bound.

Maybe this proof is a little bit more coplicated, than it should be, but
at least every step is followed properly.

\section*{1.3.3}
\textit{(a) Let $A$ be bounded below, and define $B = \{b \in \textbf{R}:
  b $ is a lower bound for $A\}$. Show that $sup(B) = inf(A)$.}

$B$ is a set, therefore Axiom of Completeness states that there exist real
number $k = sup(B)$. Therefore all lower bounds are less or equal to $k$.

In order to prove that $k$ is infinum, we need to show that it is a lower
bound.

We do it by contradiction: suppose that $k$ is not a lower bound. Therefore
there exists $a \in A$ such that $k > a$. Let $\epsilon = k - a > 0$. Then,
because $k = sup(B)$ there exist $b \in B$ such that $k - \epsilon < b$.
Therefore $a < b$. Therefore there exist an element of $A$, that is less than
lower bound of $A$. Therefore $b$ is not a lower bound. Therefore we have a
contradiction. Thus $k$ is a lower bound.

Because $k$ is a lower bound, $k \in B$ by definition of $B$. Therefore it is
a lower bound, that is greater or equal to any other lower bounds, because it
is a supremum of $B$. Therefore it is an infinum of $A$ by definition of
infinum.

\textit{(b) Use (a) to explain why there is no need to assert that greatest
  upper bound exist as part of the Axiom of Completeness.}

Proof of part (a) does not take into account the fact, that $A$ (that is
bounded below) has an infinum. We prove its existence of the infinum by
the fact, that we have a set of lower bounds (which is in its turn
has a supremum by Axiom of Completeness), and setting the fact, that its
supremum is lower bound itself  and therefore proving that it is in the set of
lower bounds and therefore setting the fact, that it exists.

\textit{(c) Propose another way to use the Axiom of Completeness to prove
  that sets bounded below have greatest lower bounds.}

The only idea, that goes into my mind is to create set $B = \{-a: a \in A\}$.
Then it'll have a supremum, for which the inverse will be the infinum of the
set. We can polish this idea with some theorems and axioms, but I'm satisfied
with the current proof already, and nobody is requiring it.

\section*{1.3.4}
\textit{Assume that $A$ abd $B$ are nonempty, bounded above, and satisfy
  $B \subseteq A$. Show $sup(B) \leq sup(A)$.}

We prove it by contradiction: let $B \subseteq A$ and
$$sup(B) > sup(A)$$

Then let $\epsilon = sup(B) - sup(A) > 0$. Then by lemma we have

$$b \in B: b > sup(B) - \epsilon$$
$$b \in B: b > sup(B) - sup(B) + sup(A)$$
$$b \in B: b > sup(A)$$

Therefore $b > sup(A)$, which is an upper bound for $A$ and by extension
$\forall a \in A: b > a$. Therefore $b \notin A$ and $b \in B$. Therefore
$B \not\subseteq A$, which is a contradiction. Therefore $sup(B) \leq sup(A)$.

\section*{1.3.5}
\textit{Let $A \subseteq \textbf{R}$ be bounded above, and let $c \in
  \textbf{R}$. Define the sets $c + A$ and $cA$ by $c + A = \{c + a: a \in A\}$
  and  $cA = \{ca: a \in A\}$
}

\textit{(a) Show that $sup(c + A) = c + sup(A)$.}

% $$\forall a \in A: a \leq sup(A)$$
% $$\forall a \in A: c + a \leq c +  sup(A)$$
% $$n \in c + A \to \exists a \in A: n = c + a$$
% $$\forall n \in c + A: n \leq c + sup(A)$$

% $c + sup(A)$ is an upper bound of c + A
We gonna prove it by contradiction

Suppose $c + sup(A)$ is not an upper bound of $c + A$. Then
$$\exists n \in c + A: n > c + sup(A)$$
let us call such element $l$;
also, by the definition of $c + A$
$$\forall n \in c + A : \exists a \in A: c + a = n$$
therefore
$$\exists a \in A: c + a = l$$
because $l > c + sup(A)$
$$c + a > c + sup(A)$$
$$a > sup(A)$$
Which is a contradiction. Therefore $c + sup(A)$ is an upper bound for $c + A$.

Suppose $c + sup(A) \neq sup(c + A)$. Then $sup(c + A)$ is less
than $c + sup(A)$. Let $\epsilon = c + sup(A) - sup(c + A)$. Then

$$\exists k \in A: k > sup(A) - \epsilon$$
$$k > sup(A) - c - sup(A) + sup(c + A)$$
$$k > - c  + sup(c + A)$$

Therefore
$$\exists h \in c + A: h = k + c$$
$$h - c = k$$
$$h - c >  -c + sup(c + A)$$
$$h > sup(c + A)$$

therefore

$$\exists h \in c + A: h > sup(c + A)$$

which is a contradiction. Therefore $c + sup(A) = sup(c + A)$, as desired.

\textit{(b) If $c \geq 0$, show that $sup(cA) = c * sup(A)$}

If $c = 0$, then it $cA = \{0\}$, and the case is trivial. Therefore let's
discuss further case when $c > 0$.

Suppose $c * sup(A)$ is not an upper bound for $cA$.

Then
$$\exists q \in cA: q > c * sup(A)$$
by the definition of $cA$
$$\exists j \in A: q = cj$$
therefore
$$q > c * sup(A)$$
$$cj > c * sup(A)$$
$$j > sup(A)$$

Which is a contradiction, because $j \in A$. Therefore $c * sup(A)$ is an
upper bound for $cA$.

Suppose $c *sup(A) \neq sup(cA)$. Then $sup(c A)$ is less
than $c * sup(A)$.

$$c * sup(A) > sup(cA)$$
$$c * sup(A) - sup(cA) > 0$$
$$\frac{c * sup(A) - sup(cA)}{c} > 0$$
% $$\frac{c * sup(A) - sup(cA)}{c} > 0$$

Let $\epsilon = \frac{c * sup(A) - sup(cA)}{c}$. Then


$$\exists k \in A: k > sup(A) - \epsilon$$
$$k > sup(A) - \frac{c * sup(A) - sup(cA)}{c}$$
$$k > sup(A) - sup(A) - sup(cA)/c$$
$$k > sup(cA)/c$$

Therefore
$$\exists h \in cA: h = ck$$
$$h/c = k$$
$$h/c>  sup(cA)/c$$
$$h > sup(cA)$$

therefore

$$\exists h \in cA: h > sup(cA)$$

Which is a contradiction. Therefore $sup(cA) = c * sup(A)$ as desired.

\textit{(c) Postulate a simular type of statement for $sup(cA)$ for the case
  $c < 0$}

Proposition: suppose that $A$ is bounded below;  if $c < 0$ then $sup(cA) = c
* inf(A)$

Suppose $c * inf(A)$ is not an upper bound for $cA$.

Then
$$\exists q \in cA: q > c * inf(A)$$
by the definition of $cA$
$$\exists j \in A: q = cj$$
therefore
$$q > c * inf(A)$$
$$cj > c * inf(A)$$
$$j < inf(A)$$

Which is a contradiction, because $j \in A$. Therefore $c * sup(A)$ is an
upper bound for $cA$.

Suppose $c * inf(A) \neq sup(cA)$. Then $sup(c A)$ is less
than $c * inf(A)$.

$$sup(cA) < c * inf(A)$$
$$sup(cA) - c * inf(A) < 0$$
$$\frac{sup(cA) - c * inf(A)}{c} > 0$$

Let $\epsilon = \frac{sup(cA) - c * inf(A)}{c} > 0$. Then

$$\exists k \in A: k < inf(A) + \epsilon$$
$$ k < inf(A) + \epsilon$$
$$ k < inf(A) + \frac{sup(cA) - c * inf(A)}{c}$$
$$ k < inf(A) + sup(cA)/c - inf(A)$$
$$ k < sup(cA)/c$$

Therefore

$$\exists h \in cA: h = ck$$
$$h/c = k$$
$$h/c = k < sup(cA) / c$$
$$h/c < sup(cA) / c$$
$$h > sup(cA)$$
therefore

$$\exists h \in cA: h > sup(cA)$$

Which is a contradiction. Therefore $sup(cA) = c * inf(A)$ as desired.

\section*{1.3.6}
\textit{Compute, without proofs, the suprema and infima of the following
  sets:}

\textit{(a) $\{n \in \textbf{N}: n^2 < 10\}$}

$sup = 3$, $inf = 1$.

\textit{(b) $\{n/(m + n): m,n\in \textbf{N}\}$}

$sup = 1/2$, $inf = 0$.

\textit{(c) $\{n/(2n + 1): n\in \textbf{N}\}$}

$sup = 1/2$, $inf = 1/3$.

\textit{(d) $\{n/m: m,n\in \textbf{N}$ with $m + n \leq 10\}$}

$sup = 9$, $inf = 1/9$.

\section*{1.3.7}
\textit{Prove that if $a$ is an upper bound for $A$, and if $a$ is also an
  element $A$, then it must be that $a = sup(A)$}

Let's prove this one by contradiction

Suppose that $a \neq sup(A)$. Because $a$ is still an upper bound, $sup(A) <
a$, Therefore $a \in A$, but $sup(A) < a$, which is a contradiction.
Therefore $a = sup(A)$.

\section*{1.3.8}
\textit{If $sup(A) < sup(B)$, then show that there exists an element $b \in B$,
  that is an upper bound for $A$.}

Let $\epsilon = sup(B) - sup(A)$. Then

$$\exists b \in B: b > sup(B) - \epsilon$$
$$ b > sup(B) - \epsilon $$
$$ b > sup(B) - sup(B) + sup(A) $$
$$ b > sup(A) $$

therefore $b$ is an upper bound for $A$.

\section*{1.3.9}
\textit{Without worryong about formal proofs for the moment, decide if the
  following statements about suprema and infima are true or false. For any that
  are false, supply an example where the claim in question does not appear to
  hold.}

\textit{(a) A finite, nonempty set always contains its supremum}

True

\textit{(b) If $a < L$ for every element $a$ in the set $A$, then $sup(A) <
  L$.}
False. $sup((0, 1)) = 1$; $\forall a \in (0, 1): a < 1$, therefore $sup(A) = L$.

\textit{(c) If A and B are sets with the property that $a < b$ for every
  $a \in A$ and $b \in B$, then it follows that $sup(a) < inf(B)$}

False. $sup((0,1)) = inf((1, 2))$

\textit{(d) If $sup(A) = s$ and $sup(B) = t$, then $sup(A + B) = s + t$. The
  set $A + B$ is defined as $A + B = \{a + b: a \in A$ and $b \in B\}$.}

True

\textit{(e) If $sup(A) \leq sup(B)$, then there exists an element $b \in B$
  that is an upper bound for $A$.}

False. $sup([1, 2]) = sup((1, 2))$


\end{document}
